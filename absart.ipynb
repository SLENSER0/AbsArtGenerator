{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8nxHSJTnjqWq"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import DataLoader\n",
        "from torchvision.datasets import ImageFolder\n",
        "import torchvision.transforms as T\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "\n",
        "from torchvision.utils import make_grid\n",
        "from torchvision.utils import save_image\n",
        "from torchvision.io import read_image\n",
        "import torch.nn.functional as F\n",
        "import matplotlib.pyplot as plt\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "\n",
        "from tqdm import tqdm\n",
        "\n",
        "import os\n",
        "\n",
        "#!pip install opendatasets\n",
        "import opendatasets as od\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "wnG8J96NkQWi",
        "outputId": "6965e86e-d2f3-453d-aa84-88da3e357534"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'cuda'"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "image_size = 128\n",
        "batch_size = 128\n",
        "stats = (0.5, 0.5, 0.5), (0.5, 0.5, 0.5)\n",
        "latent_size = 128\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "lr = 2e-4\n",
        "device"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wo4pLxQdkaq0",
        "outputId": "aa9b12c4-2468-455b-cd9c-0f662c12e651"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Please provide your Kaggle credentials to download this dataset. Learn more: http://bit.ly/kaggle-creds\n",
            "Your Kaggle username: slenser\n",
            "Your Kaggle Key: ··········\n",
            "Downloading abstract-art.zip to ./abstract-art\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 296M/296M [00:03<00:00, 82.6MB/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "od.download('https://www.kaggle.com/datasets/greg115/abstract-art')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QoRk0IPykcKC"
      },
      "outputs": [],
      "source": [
        "transforms = T.Compose([T.Resize((128,128)),\n",
        "                        T.CenterCrop(128),\n",
        "                        T.RandomHorizontalFlip(),\n",
        "                        T.RandomVerticalFlip(),\n",
        "                        T.ToTensor(),\n",
        "                        T.Normalize(*stats)])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M60Y2COdk_F8"
      },
      "outputs": [],
      "source": [
        "def denorm(img_tensor):\n",
        "    return img_tensor * stats[1][0] + stats[0][0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "geCHZNxUlJEB"
      },
      "outputs": [],
      "source": [
        "train_ds = ImageFolder(root='/content/abstract-art', transform=transforms)\n",
        "train_dl = DataLoader(train_ds, batch_size, shuffle=True, num_workers=0, pin_memory=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mpabHC2HlM7B"
      },
      "outputs": [],
      "source": [
        "def show_image(train_dl):\n",
        "  for images,_ in train_dl:\n",
        "      fig, ax = plt.subplots(figsize=(8,8))\n",
        "      ax.set_xticks([]); ax.set_yticks([])\n",
        "      ax.imshow(make_grid(denorm(images.detach()[:32]), nrow=8).permute(1,2,0))\n",
        "      break\n",
        "        "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h-7d3PGMlTlU"
      },
      "outputs": [],
      "source": [
        "def to_device(data, device):\n",
        "    if isinstance(data, (list,tuple)):\n",
        "        return [to_device(x, device) for x in data]\n",
        "    return data.to(device, non_blocking=True)\n",
        "\n",
        "class DeviceDataLoader():\n",
        "    def __init__(self, dl, device):\n",
        "        self.dl = dl\n",
        "        self.device = device\n",
        "        \n",
        "    def __iter__(self):\n",
        "        for x in self.dl:\n",
        "            yield to_device(x, self.device)\n",
        "            \n",
        "    def __len__(self):\n",
        "        return len(self.dl)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7YUFpnRqnQ5O"
      },
      "outputs": [],
      "source": [
        "train_dl = DeviceDataLoader(train_dl, device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rqdYlB7VnWWt"
      },
      "outputs": [],
      "source": [
        "class Discriminator(nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    self.disc = nn.Sequential(\n",
        "    nn.Conv2d(3, 64, 4, 2, 1, bias=False),\n",
        "    nn.BatchNorm2d(64),\n",
        "    nn.LeakyReLU(0.2, inplace=True),\n",
        "    \n",
        "    nn.Conv2d(64, 128,4, 2, 1, bias=False),\n",
        "    nn.BatchNorm2d(128),\n",
        "    nn.LeakyReLU(0.2, inplace=True),\n",
        "    \n",
        "    nn.Conv2d(128, 256,4, stride=2, padding=1, bias=False),\n",
        "    nn.BatchNorm2d(256),\n",
        "    nn.LeakyReLU(0.2, inplace=True),\n",
        "    \n",
        "    nn.Conv2d(256, 512, 4, 2, 1, bias=False),\n",
        "    nn.BatchNorm2d(512),\n",
        "    nn.LeakyReLU(0.2, inplace=True),\n",
        "    \n",
        "    nn.Conv2d(512, 1024, 4, 2, 1, bias=False),\n",
        "    nn.BatchNorm2d(1024),\n",
        "    nn.LeakyReLU(0.2, inplace=True),\n",
        "    \n",
        "    nn.Conv2d(1024, 1, 4, 1, 0, bias=False),\n",
        "    \n",
        "    nn.Flatten(),\n",
        "    nn.Sigmoid()\n",
        "    )\n",
        "  def forward(self, x):\n",
        "    return self.disc(x)\n",
        "\n",
        "class Generator(nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    self.gen = nn.Sequential(\n",
        "        \n",
        "  \n",
        "    nn.ConvTranspose2d(latent_size, 1024, kernel_size=4, stride=1, padding=0, bias=False),\n",
        "    nn.BatchNorm2d(1024),\n",
        "    nn.ReLU(True),\n",
        "    \n",
        "    nn.ConvTranspose2d(1024, 512, kernel_size=4, stride=2, padding=1, bias=False),\n",
        "    nn.BatchNorm2d(512),\n",
        "    nn.ReLU(True),\n",
        "    \n",
        "    nn.ConvTranspose2d(512, 256, kernel_size=4, stride=2, padding=1, bias=False),\n",
        "    nn.BatchNorm2d(256),\n",
        "    nn.ReLU(True),\n",
        "    \n",
        "    nn.ConvTranspose2d(256, 128, kernel_size=4, stride=2, padding=1, bias=False),\n",
        "    nn.BatchNorm2d(128),\n",
        "    nn.ReLU(True),\n",
        "    \n",
        "    nn.ConvTranspose2d(128, 64, kernel_size=4, stride=2, padding=1, bias=False),\n",
        "    nn.BatchNorm2d(64),\n",
        "    nn.ReLU(True),\n",
        "    \n",
        "    nn.ConvTranspose2d(64, 3, kernel_size=4, stride=2, padding=1, bias=False),\n",
        "    nn.Tanh()\n",
        "    )\n",
        "  def forward(self, x):\n",
        "    return self.gen(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5YbF5CTVorPR"
      },
      "outputs": [],
      "source": [
        "D = Discriminator().to(device)\n",
        "G = Generator().to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E2pykymRpGDw"
      },
      "outputs": [],
      "source": [
        "def train_discriminator(real_images, opt_d):\n",
        "    opt_d.zero_grad()\n",
        "    \n",
        "    real_preds= D(real_images) \n",
        "    real_targets = torch.ones(real_images.size(0), 1, device=device)\n",
        "    real_loss = F.binary_cross_entropy(real_preds, real_targets) \n",
        "    real_score = torch.mean(real_preds).item()\n",
        "    \n",
        "    latent = torch.randn(latent_size, latent_size, 1, 1, device=device)\n",
        "    fake_images = G(latent)\n",
        "    \n",
        "    fake_preds= D(fake_images)\n",
        "    fake_targets = torch.zeros(fake_images.size(0), 1, device=device)\n",
        "    fake_loss = F.binary_cross_entropy(fake_preds, fake_targets)\n",
        "    fake_score = torch.mean(fake_preds).item()\n",
        "    \n",
        "    loss = real_loss + fake_loss\n",
        "    loss.backward(),\n",
        "    opt_d.step()\n",
        "    \n",
        "    return loss.item(), real_score, fake_score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-X5hXpvZp9Se"
      },
      "outputs": [],
      "source": [
        "def train_generator(opt_g):\n",
        "    opt_g.zero_grad()\n",
        "    \n",
        "    latent = torch.randn(latent_size, latent_size, 1, 1, device=device)\n",
        "    fake_images = G(latent)\n",
        "    \n",
        "    preds = D(fake_images)\n",
        "    targets = torch.ones(fake_images.size(0), 1, device=device)\n",
        "    loss = F.binary_cross_entropy(preds, targets)\n",
        "    \n",
        "    loss.backward(),\n",
        "    opt_g.step()\n",
        "    \n",
        "    return loss.item()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q0Oo7YVnqC9N",
        "outputId": "ce8cd13a-e536-452b-9b10-ab1953eb7fb6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iz6x8qyjr9AR"
      },
      "outputs": [],
      "source": [
        "sample_dir = \"/content/gdrive/My Drive/genn\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xTZhtX9fq5I-"
      },
      "outputs": [],
      "source": [
        "def save_sample(index, fixed_latent, show=True):\n",
        "    fake_images = G(fixed_latent)\n",
        "    fake_fname = \"img{0}.png\".format(index)\n",
        "    save_image(denorm(fake_images), os.path.join(sample_dir, fake_fname), nrow=8)\n",
        "    if show:\n",
        "        fig, ax = plt.subplots(figsize=(8,8))\n",
        "        ax.set_xticks([]); ax.set_yticks([])\n",
        "        ax.imshow(make_grid(fake_images.cpu().detach()[:32], nrow=8).permute(1,2,0))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vlgnT4WDsx2a"
      },
      "outputs": [],
      "source": [
        "fixed_latent = torch.randn(128, latent_size, 1, 1, device=device)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JVW3PbzRszhn"
      },
      "outputs": [],
      "source": [
        "def fit(epochs, lr_d, lr_g, start_idx=1):\n",
        "    torch.cuda.empty_cache()\n",
        "    \n",
        "    opt_d = torch.optim.Adam(D.parameters(), lr=lr_d, betas=(0.5, 0.999))\n",
        "    opt_g = torch.optim.Adam(G.parameters(), lr=lr_g, betas=(0.5, 0.999))\n",
        "    \n",
        "    for epoch in range(epochs):\n",
        "        for real_images,_ in tqdm(train_dl):\n",
        "            loss_d, real_score, fake_score = train_discriminator(real_images, opt_d)\n",
        "            loss_g = train_generator(opt_g)\n",
        "        if (epoch+1)%10==0:\n",
        "            model_save_name = F'Generaotr{epoch}.pt'\n",
        "            path = F\"/content/gdrive/My Drive/{model_save_name}\" \n",
        "            torch.save(G.state_dict(), path)\n",
        "\n",
        "        print(\"Epoch: [{}/{}], loss_d: {:.4f}, loss_g: {:.4f}, real_score: {:.4f}, fake_score: {:.4f}\".format(\n",
        "        epoch+1, epochs, loss_d, loss_g, real_score, fake_score))\n",
        "        \n",
        "        save_sample(epoch+start_idx, fixed_latent, show=False)\n",
        "        "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n1rJ7xc5tIsx"
      },
      "outputs": [],
      "source": [
        "epochs = 300\n",
        "lr_d = 10e-5\n",
        "lr_g = 10e-4"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "D2GABEostK2M"
      },
      "outputs": [],
      "source": [
        "fit(epochs, lr_d, lr_g, start_idx=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "07oyRWRPtlUO"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "machine_shape": "hm",
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}